#-*- coding: utf-8 -*-

# DPM でクラスタリングする方法は，同じ初期状態で
# 教示されたとき限定だったので，作戦を変更して
# 動的計画法っぽくマッチングを行う

# 手順について
#   0. 全データの状態0, 1 をそれぞれB, A とする
#       X を一つ目のデータとする
#   1. Aが最終状態t なら，そのデータをこれ以降無視する
#   2. それらを使って一つ抜き法を計算する
#   3. 予測が最低だったものを「違うステップを見てる」
#       と仮定し，X とする
#   4. X が変更しないなら，今のB, A の組を最適として，
#       output.append(B_List) して B <- A, A <- A+1 する
#       1. に戻る
#   5. X のA 以降のt以外の全状態に対して一つ抜き法で
#       評価し，A をそのうち最高のものに更新する
#       1. に戻る

# 上記の方法だと，「分割が十分でないデータ」が一つあると
# うまく収束しない
# これでうまくいくかどうかは実際の途中状態を見てみないと
# 判断できない
# 上記がうまくいくには「A <- A+1 の段階で大多数が正しく
# マッチングできている」かつ「正しくマッチングできてない
# データは分割しすぎによるもので，A+1以降に正しく
# マッチングできる状態が存在する」という仮定が必要
# 1個目はともかく2個目が難しい
# 逆向きの計算で解決できる？
# 上記がうまくいかない場合は「動作Xが外れ値的動作」または
# 「A は部分的な途中状態」
# ↓
# 「外れ値」として処理して「部分的な途中状態」を作成しよう
# それ以降の推定は，そこで生成したモデルを利用して
# 外れ値的な動作に対して新たな途中状態を作成し，そこをB
# として行う.
# これは「外れ値」として省いたデータの量と，推定結果の
# 妥当性を評価して，実際に使うかを決めるべき
# ↓
# そういえば，「ある程度ご教示があっても対応可能」というのが
# 卒論の結論だったわけだから，得られたAで学習しちゃえば
# いいわけだ．それで推定を行って，次のBには「推定結果」を
# 入れる，という風にしようか
# 推定結果の妥当性はnaiveと比較すれば判断できるはず
# 推定結果が実際とかけ離れている場合，X（この時点では
# まだ残っているはず）を無視してもう一度 A の推定から
# やり直す
# Xとは「一つ抜き法で最も『抜いたほうがいい』」とされた動作
# Bは推定結果とするのではなく，「推定結果に最も近いnaiveの
# 一点」とした方が自然っぽい
# ↓
# というわけで手順再考
#   0. 全データの状態0, 1 をそれぞれB, A とする
#       X を一つ目のデータとする
#   1. Aが最終状態t なら，そのデータをこれ以降無視する
#   2. それらを使って一つ抜き法を計算する
#   3. 予測が最低だったものを「違うステップを見てる」
#       と仮定し，X とする
#   4. X が変化したなら，X のA 以降のt以外の全状態に対して
#       一つ抜き法で評価し，A をそのうち最高のものに更新する
#       1. に戻る
#   5. X が変更しないなら，今のB, A の組を最適として，
#       Model(B->A)を学習する
#   6. Model(B->A)をもとにA'を求め，naive の中からA'に
#       最も近い状態 Anew を取得する
#   7. Anew がA' とかけ離れていた場合，X を無視して
#       2. に戻る
#   8. B <- A, A<-Anew して 1. に戻る

import ViewPointManager
import ViewPointEncoder

output = []
